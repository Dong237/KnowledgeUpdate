{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Debug Finetuning Script",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/finetune.py",
            "args": [
                // ModleArguments
                "--model_name_or_path", "/data/repos/huggingface/gpt2", // /data/repos/huggingface/Qwen2.5-1.5B-Instruct-GPTQ-Int8
                // DataArgumens
                "--data_path", "/data/repos/KnowledgeUpdate/datasets/sample.json",
                "--evaluation_strategy", "no",
                "--lazy_preprocess", "False",
                // WandbArguments
                "--key", "e28afd6154b7ecd865dde62fead55bba5994bc9a",
                "--use_wandb", "True",
                "--wandb_run_name", "debug-run1",
                // TrainingArguments
                "--cache_dir", "/data/repos/huggingface/.cache",
                "--bf16", "True",
                "--output_dir", "output_qwen/7B_debug",
                "--num_train_epochs", "1",
                "--per_device_train_batch_size", "2",
                "--per_device_eval_batch_size", "1",
                "--gradient_accumulation_steps", "4",
                "--learning_rate", "3e-4",
                "--weight_decay", "0.1",
                "--adam_beta2", "0.95",
                "--warmup_ratio", "0.01",
                "--lr_scheduler_type", "cosine",
                "--model_max_length", "512",
                "--use_lora",
                "--gradient_checkpointing",
                // "--deepspeed", "/data/repos/KnowledgeUpdate/ds_config_zero2.json"
                // LoraArguments

            ],
            "env": {
                "CUDA_DEVICE_MAX_CONNECTIONS": "1"
            },
            "console": "integratedTerminal",
        },
        {
            "name": "Debug Data Collection Script",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/data_collection.py",
            "args":  [
                "--data_path", "/data/youxiang/repos/KnowledgeUpdate/datasets/txt_data_sample",
                "--chunk_size_by_token", "1024",
                "--qa_amount_per_fact", "10",
                "--role_amount_per_fact", "1",
                "--json_save_dir", "datasets/qa_pairs_debug.json",
                "--num_workers", "8",
            ],
            "console": "integratedTerminal",
        },
        {
            "name": "Debug Inference Script",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/inference.py",
            "args": [
                "--model_name_or_path", "/data/tangbo/plms/Qwen2.5-7B-Instruct-GPTQ-Int8",
                "--test_data_path", "datasets/test_dataset.json",
                "--output_path", "results/inference_results.json",
                "--lora_weights", "/data/youxiang/repos/KnowledgeUpdate/output_qwen/7B_5epochs"
            ],
            "console": "integratedTerminal",
        },
        {
            "name": "Debug Evaluate Script",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/evaluate.py",
            "args": [
                "--data_path", "results", 
                "--data_name_sft", "inference_results_sft_5epochs.json", 
                "--data_name_base", "inference_results_base.json", 
                "--max_attempts", "5", 
                "--retry_delay", "2",
                "--local_model_path", "/data/youxiang/huggingface/Qwen2.5-14B-Instruct-GPTQ-Int8"
            ],
            "console": "integratedTerminal",
        }
    ]
}

